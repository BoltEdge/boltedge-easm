"""add group schedule support

Revision ID: a64ffb4308db
Revises: 029c573fe4a1
Create Date: 2026-02-08 15:39:43.122984

"""
from alembic import op
import sqlalchemy as sa


# revision identifiers, used by Alembic.
revision = 'a64ffb4308db'
down_revision = '029c573fe4a1'
branch_labels = None
depends_on = None


def upgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    with op.batch_alter_table('discovery_runs', schema=None) as batch_op:
        batch_op.drop_index(batch_op.f('idx_discovery_runs_org_created'))

    op.drop_table('discovery_runs')
    with op.batch_alter_table('scan_historical_data', schema=None) as batch_op:
        batch_op.alter_column('asset_id',
               existing_type=sa.INTEGER(),
               nullable=True)
        batch_op.drop_index(batch_op.f('ix_scan_historical_data_asset_id'))
        batch_op.drop_constraint(None, type_='foreignkey')
        batch_op.create_foreign_key(None, 'asset', ['asset_id'], ['id'])

    with op.batch_alter_table('scan_job', schema=None) as batch_op:
        batch_op.alter_column('scan_engines',
               existing_type=sa.TEXT(),
               type_=sa.JSON(),
               existing_nullable=True)
        batch_op.create_foreign_key(None, 'scan_schedule', ['schedule_id'], ['id'], ondelete='SET NULL')
        batch_op.create_foreign_key(None, 'scan_profile', ['profile_id'], ['id'], ondelete='SET NULL')

    with op.batch_alter_table('scan_schedule', schema=None) as batch_op:
        batch_op.add_column(sa.Column('schedule_type', sa.String(length=20), nullable=False))
        batch_op.add_column(sa.Column('group_id', sa.Integer(), nullable=True))
        batch_op.create_foreign_key(None, 'asset_group', ['group_id'], ['id'])

    # ### end Alembic commands ###


def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    with op.batch_alter_table('scan_schedule', schema=None) as batch_op:
        batch_op.drop_constraint(None, type_='foreignkey')
        batch_op.drop_column('group_id')
        batch_op.drop_column('schedule_type')

    with op.batch_alter_table('scan_job', schema=None) as batch_op:
        batch_op.drop_constraint(None, type_='foreignkey')
        batch_op.drop_constraint(None, type_='foreignkey')
        batch_op.alter_column('scan_engines',
               existing_type=sa.JSON(),
               type_=sa.TEXT(),
               existing_nullable=True)

    with op.batch_alter_table('scan_historical_data', schema=None) as batch_op:
        batch_op.drop_constraint(None, type_='foreignkey')
        batch_op.create_foreign_key(None, 'asset', ['asset_id'], ['id'], ondelete='CASCADE')
        batch_op.create_index(batch_op.f('ix_scan_historical_data_asset_id'), ['asset_id'], unique=False)
        batch_op.alter_column('asset_id',
               existing_type=sa.INTEGER(),
               nullable=False)

    op.create_table('discovery_runs',
    sa.Column('id', sa.INTEGER(), nullable=True),
    sa.Column('user_id', sa.TEXT(), nullable=False),
    sa.Column('organization_id', sa.TEXT(), nullable=False),
    sa.Column('domain', sa.TEXT(), nullable=False),
    sa.Column('created_at', sa.TEXT(), nullable=False),
    sa.Column('source_flags', sa.TEXT(), nullable=False),
    sa.Column('counts', sa.TEXT(), nullable=False),
    sa.Column('limits', sa.TEXT(), nullable=False),
    sa.Column('result_json', sa.TEXT(), nullable=False),
    sa.PrimaryKeyConstraint('id')
    )
    with op.batch_alter_table('discovery_runs', schema=None) as batch_op:
        batch_op.create_index(batch_op.f('idx_discovery_runs_org_created'), ['organization_id', 'created_at'], unique=False)

    # ### end Alembic commands ###
